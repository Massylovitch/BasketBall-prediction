{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11f7bb5d-6222-4478-a231-09c27102a556",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a6e6b9-f500-4465-9427-f6c16d96a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# from src.common_functions import plot_corr_barchart, plot_corr_vs_target, run_sweetviz_report\n",
    "\n",
    "from pathlib import Path  #for Windows/Linux compatibility\n",
    "DATAPATH = Path(r'../data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8765810b-aa24-4901-a2aa-2d2d57a7b921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_DATE_EST</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>HOME_TEAM_ID</th>\n",
       "      <th>VISITOR_TEAM_ID</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>PTS_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>FG3_PCT_home</th>\n",
       "      <th>AST_home</th>\n",
       "      <th>REB_home</th>\n",
       "      <th>PTS_away</th>\n",
       "      <th>FG_PCT_away</th>\n",
       "      <th>FT_PCT_away</th>\n",
       "      <th>FG3_PCT_away</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>REB_away</th>\n",
       "      <th>HOME_TEAM_WINS</th>\n",
       "      <th>PLAYOFF</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-16</td>\n",
       "      <td>42100406</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>2021</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.393</td>\n",
       "      <td>27.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.413</td>\n",
       "      <td>27.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>42100405</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>2021</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.225</td>\n",
       "      <td>23.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.344</td>\n",
       "      <td>18.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>42100404</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>2021</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.395</td>\n",
       "      <td>22.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.349</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>42100403</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>2021</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.371</td>\n",
       "      <td>28.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.375</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-05</td>\n",
       "      <td>42100402</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>2021</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.405</td>\n",
       "      <td>25.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.405</td>\n",
       "      <td>24.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24366</th>\n",
       "      <td>2014-10-29</td>\n",
       "      <td>21400014</td>\n",
       "      <td>1610612758</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>2014</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.167</td>\n",
       "      <td>13.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.222</td>\n",
       "      <td>21.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24367</th>\n",
       "      <td>2014-10-29</td>\n",
       "      <td>21400015</td>\n",
       "      <td>1610612757</td>\n",
       "      <td>1610612760</td>\n",
       "      <td>2014</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.379</td>\n",
       "      <td>23.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.125</td>\n",
       "      <td>19.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24368</th>\n",
       "      <td>2014-10-28</td>\n",
       "      <td>21400001</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>1610612753</td>\n",
       "      <td>2014</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.235</td>\n",
       "      <td>20.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.364</td>\n",
       "      <td>17.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24369</th>\n",
       "      <td>2014-10-28</td>\n",
       "      <td>21400002</td>\n",
       "      <td>1610612759</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>2014</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.500</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.381</td>\n",
       "      <td>17.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24370</th>\n",
       "      <td>2014-10-28</td>\n",
       "      <td>21400003</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>1610612745</td>\n",
       "      <td>2014</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.300</td>\n",
       "      <td>16.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.414</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24371 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GAME_DATE_EST   GAME_ID  HOME_TEAM_ID  VISITOR_TEAM_ID  SEASON  \\\n",
       "0        2022-06-16  42100406    1610612738       1610612744    2021   \n",
       "1        2022-06-13  42100405    1610612744       1610612738    2021   \n",
       "2        2022-06-10  42100404    1610612738       1610612744    2021   \n",
       "3        2022-06-08  42100403    1610612738       1610612744    2021   \n",
       "4        2022-06-05  42100402    1610612744       1610612738    2021   \n",
       "...             ...       ...           ...              ...     ...   \n",
       "24366    2014-10-29  21400014    1610612758       1610612744    2014   \n",
       "24367    2014-10-29  21400015    1610612757       1610612760    2014   \n",
       "24368    2014-10-28  21400001    1610612740       1610612753    2014   \n",
       "24369    2014-10-28  21400002    1610612759       1610612742    2014   \n",
       "24370    2014-10-28  21400003    1610612747       1610612745    2014   \n",
       "\n",
       "       PTS_home  FG_PCT_home  FT_PCT_home  FG3_PCT_home  AST_home  REB_home  \\\n",
       "0          90.0        0.425        0.917         0.393      27.0      41.0   \n",
       "1         104.0        0.466        0.867         0.225      23.0      39.0   \n",
       "2          97.0        0.400        0.737         0.395      22.0      42.0   \n",
       "3         116.0        0.483        0.708         0.371      28.0      47.0   \n",
       "4         107.0        0.453        0.700         0.405      25.0      42.0   \n",
       "...         ...          ...          ...           ...       ...       ...   \n",
       "24366      77.0        0.308        0.743         0.167      13.0      50.0   \n",
       "24367     106.0        0.448        0.773         0.379      23.0      42.0   \n",
       "24368     101.0        0.406        0.484         0.235      20.0      62.0   \n",
       "24369     101.0        0.529        0.813         0.500      23.0      38.0   \n",
       "24370      90.0        0.354        0.795         0.300      16.0      36.0   \n",
       "\n",
       "       PTS_away  FG_PCT_away  FT_PCT_away  FG3_PCT_away  AST_away  REB_away  \\\n",
       "0         103.0        0.413        1.000         0.413      27.0      44.0   \n",
       "1          94.0        0.413        0.677         0.344      18.0      47.0   \n",
       "2         107.0        0.440        0.800         0.349      20.0      55.0   \n",
       "3         100.0        0.462        0.867         0.375      22.0      31.0   \n",
       "4          88.0        0.375        0.765         0.405      24.0      43.0   \n",
       "...         ...          ...          ...           ...       ...       ...   \n",
       "24366      95.0        0.440        0.719         0.222      21.0      44.0   \n",
       "24367      89.0        0.407        0.808         0.125      19.0      43.0   \n",
       "24368      84.0        0.381        0.762         0.364      17.0      56.0   \n",
       "24369     100.0        0.487        0.842         0.381      17.0      33.0   \n",
       "24370     108.0        0.425        0.680         0.414      22.0      47.0   \n",
       "\n",
       "       HOME_TEAM_WINS  PLAYOFF  TARGET  \n",
       "0                   0        1       0  \n",
       "1                   1        1       1  \n",
       "2                   0        1       0  \n",
       "3                   1        1       1  \n",
       "4                   1        1       1  \n",
       "...               ...      ...     ...  \n",
       "24366               0        0       0  \n",
       "24367               1        0       1  \n",
       "24368               1        0       1  \n",
       "24369               1        0       1  \n",
       "24370               0        0       0  \n",
       "\n",
       "[24371 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(DATAPATH / \"processed\" / \"train.csv\")\n",
    "test = pd.read_csv(DATAPATH / \"processed\" / \"test.csv\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7de2db65-2803-45c0-831f-23423c610078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_datatypes(df):\n",
    "    if df.GAME_DATE_EST.dtype == \"O\":\n",
    "        df['GAME_DATE_EST'] = df['GAME_DATE_EST'].str.split(\" \").str[0]\n",
    "    \n",
    "    df['GAME_DATE_EST'] = pd.to_datetime(df['GAME_DATE_EST'])\n",
    "\n",
    "    long_integer_fields = ['GAME_ID', 'HOME_TEAM_ID', 'VISITOR_TEAM_ID', 'SEASON']\n",
    "\n",
    "    #convert long integer fields to int32 from int64\n",
    "    for field in long_integer_fields:\n",
    "        df[field] = df[field].astype('int32')\n",
    "    \n",
    "    #convert the remaining int64s to int8\n",
    "    for field in df.select_dtypes(include=['int64']).columns.tolist():\n",
    "        df[field] = df[field].astype('int8')\n",
    "        \n",
    "    #convert float64s to float16s\n",
    "    for field in df.select_dtypes(include=['float64']).columns.tolist():\n",
    "        df[field] = df[field].astype('float16')\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7964066-6860-46a1-8383-ca0edbf4b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_features(df):\n",
    "    #convert game date to month to limit cardinality\n",
    "\n",
    "    df['MONTH'] = df['GAME_DATE_EST'].dt.month\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3640ba5-1f7a-4c51-bed8-dd58054d60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_playoff_games(df):\n",
    "    \n",
    "    df = df[df[\"PLAYOFF\"] == 0]\n",
    "    \n",
    "    df = df.drop(\"PLAYOFF\", axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a8450ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_x_minus_league_avg(df, feature_list, team_feature):\n",
    "\n",
    "    # create a temp dataframe so that every date can be front-filled\n",
    "    # we need the current average for all 30 teams for every day during the season\n",
    "    # whether that team played or not. \n",
    "    # We will front-fill from previous days to ensure that every day has stats for every team\n",
    "    \n",
    "    \n",
    "    # create feature list for temp dataframe to hold league averages\n",
    "    temp_feature_list = feature_list.copy()\n",
    "    temp_feature_list.append(team_feature)\n",
    "    temp_feature_list.append(\"GAME_DATE_EST\")\n",
    "   \n",
    "    df_temp = df[temp_feature_list]\n",
    "\n",
    "    # populate the dataframe with all days played and forward fill previous value if a particular team did not play that day\n",
    "    # https://stackoverflow.com/questions/70362869\n",
    "    df_temp = (df_temp.set_index('GAME_DATE_EST')\n",
    "            .groupby([team_feature])[feature_list]\n",
    "            .apply(lambda x: x.asfreq('d', method = \"ffill\"))\n",
    "            .reset_index()\n",
    "            [temp_feature_list]\n",
    "            )\n",
    "    \n",
    "    # find the average across all teams for each day\n",
    "    df_temp = df_temp.groupby(['GAME_DATE_EST'])[feature_list].mean().reset_index()\n",
    "    \n",
    "    # rename features for merging\n",
    "    df_temp = df_temp.add_suffix('_LEAGUE_AVG')\n",
    "    temp_features = df_temp.columns\n",
    "    \n",
    "    # merge all-team averages with each record so that they can be subtracted\n",
    "    df = df.sort_values(by = 'GAME_DATE_EST', axis=0, ascending= True, ignore_index=True)   \n",
    "    df = pd.merge(df, df_temp, left_on='GAME_DATE_EST', right_on='GAME_DATE_EST_LEAGUE_AVG', how=\"left\",)\n",
    "    for feature in feature_list:\n",
    "        df[feature + \"_MINUS_LEAGUE_AVG\"] = df[feature] - df[feature + \"_LEAGUE_AVG\"]\n",
    "\n",
    "    # drop temp features that were only used for subtraction\n",
    "    df = df.drop(temp_features, axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93968e69-9d28-41c0-967d-e24614b71269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_home_visitor(df, location, roll_list): \n",
    "    \n",
    "    # location = \"HOME\" or \"VISITOR\"\n",
    "    # roll_list = list of number of games for each rolling mean, e.g. [3, 5, 7, 10, 15]\n",
    "\n",
    "    # new version 2022-10-31\n",
    "    # now ignoring season boundaries and with longer rolling means \n",
    "    # AND create a field where the all-team average is subtracted from each field\n",
    "    \n",
    "    \n",
    "    # add features showing how well the home team has done in its last home games \n",
    "    # and how well the visitor team has done in its last away games\n",
    "    # add rolling means \n",
    "    # add win streaks (negative number if losing streak)\n",
    "    # these are for the home teams last  *home* games\n",
    "    # and for the visitor teams last *away* games\n",
    "    \n",
    "    location_id = location + \"_TEAM_ID\"\n",
    "\n",
    "    # sort games by the order in which they were played for each home or visitor team\n",
    "    df = df.sort_values(by = [location_id, 'GAME_DATE_EST'], axis=0, ascending=[True, True,], ignore_index=True)\n",
    "    \n",
    "    # Win streak, negative if a losing streak\n",
    "    df[location + '_TEAM_WIN_STREAK'] = df['HOME_TEAM_WINS'].groupby((df['HOME_TEAM_WINS'].shift() != df.groupby([location_id])['HOME_TEAM_WINS'].shift(2)).cumsum()).cumcount() + 1\n",
    "    # if home team lost the last game of the streak, then the streak must be a losing streak. make it negative\n",
    "    df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'].shift() == 0] =  -1 * df[location + '_TEAM_WIN_STREAK']\n",
    "\n",
    "    # If visitor, the streak has opposite meaning (3 wins in a row for home team is 3 losses in a row for visitor)\n",
    "    if location == 'VISITOR':\n",
    "        df[location + '_TEAM_WIN_STREAK'] = - df[location + '_TEAM_WIN_STREAK']  \n",
    "\n",
    "\n",
    "    # rolling means\n",
    "    feature_list = ['HOME_TEAM_WINS', 'PTS_home', 'FG_PCT_home', 'FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home']\n",
    "    \n",
    "    if location == 'VISITOR':\n",
    "        feature_list = ['HOME_TEAM_WINS', 'PTS_away', 'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away', 'REB_away']\n",
    "    \n",
    "      \n",
    "    roll_feature_list = []\n",
    "    for feature in feature_list:\n",
    "        for roll in roll_list:\n",
    "            roll_feature_name = location + '_' + feature + '_AVG_LAST_' + str(roll) + '_' + location\n",
    "            if feature == 'HOME_TEAM_WINS': #remove the \"HOME_\" for better readability\n",
    "                roll_feature_name = location + '_' + feature[5:] + '_AVG_LAST_' + str(roll) + '_' + location\n",
    "            roll_feature_list.append(roll_feature_name)\n",
    "            df[roll_feature_name] = df.groupby(['HOME_TEAM_ID'])[feature].rolling(roll, closed= \"left\").mean().values\n",
    "            \n",
    "    \n",
    "    \n",
    "    # determine league avg for each stat and then subtract it from the each team's avg\n",
    "    # as a measure of how well that team compares to all teams in that moment in time\n",
    "    \n",
    "    #remove win averages from roll list - the league average will always be 0.5 (half the teams win, half lose)\n",
    "    roll_feature_list = [x for x in roll_feature_list if not x.startswith('HOME_TEAM_WINS')]\n",
    "    \n",
    "    df = process_x_minus_league_avg(df, roll_feature_list, location_id)\n",
    "    \n",
    " \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0db99b8-44a7-4269-a610-89785877b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_games_consecutively(df_data):\n",
    "    # re-organize so that all of a team's games can be listed in chronological order whether HOME or VISITOR\n",
    "    # this will facilitate feature engineering (winpct vs team X, 5-game winpct, current win streak, etc...)\n",
    "    \n",
    "    #this data will need to be re-linked back to the main dataframe after all processing is done,\n",
    "    #joining TEAM1 to HOME_TEAM_ID for all records and then TEAM1 to VISITOR_TEAM_ID for all records\n",
    "    \n",
    "    #TEAM1 will be the key field. TEAM2 is used solely to process past team matchups\n",
    "\n",
    "    # all the home games for each team will be selected and then stacked with all the away games\n",
    "    \n",
    "    df_home = pd.DataFrame()\n",
    "    df_home['GAME_DATE_EST'] = df_data['GAME_DATE_EST']\n",
    "    df_home['GAME_ID'] = df_data['GAME_ID']\n",
    "    df_home['TEAM1'] = df_data['HOME_TEAM_ID']\n",
    "    df_home['TEAM1_home'] = 1\n",
    "    df_home['TEAM1_win'] = df_data['HOME_TEAM_WINS']\n",
    "    df_home['TEAM2'] = df_data['VISITOR_TEAM_ID']\n",
    "    df_home['SEASON'] = df_data['SEASON']\n",
    "    \n",
    "    df_home['PTS'] = df_data['PTS_home']\n",
    "    df_home['FG_PCT'] = df_data['FG_PCT_home']\n",
    "    df_home['FT_PCT'] = df_data['FT_PCT_home']\n",
    "    df_home['FG3_PCT'] = df_data['FG3_PCT_home']\n",
    "    df_home['AST'] = df_data['AST_home']\n",
    "    df_home['REB'] = df_data['REB_home']\n",
    "    \n",
    "    # now for visitor teams  \n",
    "\n",
    "    df_visitor = pd.DataFrame()\n",
    "    df_visitor['GAME_DATE_EST'] = df_data['GAME_DATE_EST']\n",
    "    df_visitor['GAME_ID'] = df_data['GAME_ID']\n",
    "    df_visitor['TEAM1'] = df_data['VISITOR_TEAM_ID'] \n",
    "    df_visitor['TEAM1_home'] = 0\n",
    "    df_visitor['TEAM1_win'] = df_data['HOME_TEAM_WINS'].apply(lambda x: 1 if x == 0 else 0)\n",
    "    df_visitor['TEAM2'] = df_data['HOME_TEAM_ID']\n",
    "    df_visitor['SEASON'] = df_data['SEASON']\n",
    "    \n",
    "    df_visitor['PTS'] = df_data['PTS_away']\n",
    "    df_visitor['FG_PCT'] = df_data['FG_PCT_away']\n",
    "    df_visitor['FT_PCT'] = df_data['FT_PCT_away']\n",
    "    df_visitor['FG3_PCT'] = df_data['FG3_PCT_away']\n",
    "    df_visitor['AST'] = df_data['AST_away']\n",
    "    df_visitor['REB'] = df_data['REB_away']\n",
    "\n",
    "    # merge dfs\n",
    "\n",
    "    df = pd.concat([df_home, df_visitor])\n",
    "\n",
    "    column2 = df.pop('TEAM1')\n",
    "    column3 = df.pop('TEAM1_home')\n",
    "    column4 = df.pop('TEAM2')\n",
    "    column5 = df.pop('TEAM1_win')\n",
    "\n",
    "    df.insert(2,'TEAM1', column2)\n",
    "    df.insert(3,'TEAM1_home', column3)\n",
    "    df.insert(4,'TEAM2', column4)\n",
    "    df.insert(5,'TEAM1_win', column5)\n",
    "\n",
    "    df = df.sort_values(by = ['TEAM1', 'GAME_ID'], axis=0, ascending=[True, True], ignore_index=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eaf486e-e99f-4bbd-b7f4-95fe3a5bf19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_matchups(df, roll_list):\n",
    "\n",
    "    # new version 2022-11-06\n",
    "    # now ignoring season boundaries and added roll parameters\n",
    "\n",
    "    # group all the games that 2 teams played each other \n",
    "    # calculate home team win pct and the home team win/lose streak\n",
    "    \n",
    "\n",
    "    df = df.sort_values(by = ['TEAM1', 'TEAM2','GAME_DATE_EST'], axis=0, ascending=[True, True, True], ignore_index=True)\n",
    "\n",
    "    for roll in roll_list:\n",
    "        df['MATCHUP_WINPCT_' + str(roll)] = df.groupby(['TEAM1','TEAM2'])['TEAM1_win'].rolling(roll, closed= \"left\").mean().values\n",
    "\n",
    "    df['MATCHUP_WIN_STREAK'] = df['TEAM1_win'].groupby((df['TEAM1_win'].shift() != df.groupby(['TEAM1','TEAM2'])['TEAM1_win'].shift(2)).cumsum()).cumcount() + 1\n",
    "    # if team1 lost the last game of the streak, then the streak must be a losing streak. make it negative\n",
    "    df['MATCHUP_WIN_STREAK'].loc[df['TEAM1_win'].shift() == 0] = -1 * df['MATCHUP_WIN_STREAK']\n",
    "  \n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3db72b8-c0a6-4b57-b315-58d51d5398fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_past_performance_all(df, roll_list):\n",
    "    \n",
    "    # roll_list = list of number of games for each rolling mean, e.g. [3, 5, 7, 10, 15]\n",
    "    \n",
    "    # new version 2022-11-03\n",
    "    # now ignoring season boundaries and with longer rolling means (20 and 40 games)\n",
    "    # AND create a field where the all-team average is subtracted from each field\n",
    "   \n",
    "    # add features showing how well each team has done in its last games\n",
    "    # regardless whether they were at home or away\n",
    "    # add rolling means for last 3, 5, 7, 10, 20, 40 games\n",
    "    # add win streaks (negative number if losing streak)\n",
    "    \n",
    "    #this data will need to be re-linked back to the main dataframe after all processing is done,\n",
    "    #joining TEAM1 to HOME_TEAM_ID for all records and then TEAM1 to VISITOR_TEAM_ID for all records\n",
    "    \n",
    "    #TEAM1 will be the key field. TEAM2 was used solely to process past team matchups\n",
    "\n",
    "\n",
    "    df = df.sort_values(by = ['TEAM1','GAME_DATE_EST'], axis=0, ascending=[True, True,], ignore_index=True)\n",
    "  \n",
    "    #streak of games won/lost, make negative is a losing streak\n",
    "    df['WIN_STREAK'] = df['TEAM1_win'].groupby((df['TEAM1_win'].shift() != df.groupby(['TEAM1'])['TEAM1_win'].shift(2)).cumsum()).cumcount() + 1   \n",
    "    # if team1 lost the last game of the streak, then the streak must be a losing streak. make it negative\n",
    "    df['WIN_STREAK'].loc[df['TEAM1_win'].shift() == 0]  = -1 * df['WIN_STREAK']\n",
    "    \n",
    "    #streak of games played at home/away, make negative if away streak\n",
    "    df['HOME_AWAY_STREAK'] = df['TEAM1_home'].groupby((df['TEAM1_home'].shift() != df.groupby(['TEAM1'])['TEAM1_home'].shift(2)).cumsum()).cumcount() + 1\n",
    "    # if team1 played the game of the streak away, then the streak must be an away streak. make it negative\n",
    "    df['HOME_AWAY_STREAK'].loc[df['TEAM1_home'].shift() == 0]  = -1 * df['HOME_AWAY_STREAK']\n",
    "    \n",
    "    #rolling means \n",
    "    \n",
    "    feature_list = ['TEAM1_win', 'PTS', 'FG_PCT', 'FT_PCT', 'FG3_PCT', 'AST', 'REB']\n",
    "   \n",
    "    #create new feature names based upon rolling period\n",
    "    \n",
    "    roll_feature_list =[]\n",
    "\n",
    "    for feature in feature_list:\n",
    "        for roll in roll_list:\n",
    "            roll_feature_name = feature + '_AVG_LAST_' + str(roll) + '_ALL'\n",
    "            roll_feature_list.append(roll_feature_name)\n",
    "            df[roll_feature_name] = df.groupby(['TEAM1'])[feature].rolling(roll, closed= \"left\").mean().values\n",
    "\n",
    "    \n",
    "    \n",
    "    # determine league avg for each stat and then subtract it from the each team's average\n",
    "    # as a measure of how well that team compares to all teams in that moment in time\n",
    "    \n",
    "    #remove win averages from roll list - the league average will always be 0.5 (half the teams win, half lose)\n",
    "    roll_feature_list = [x for x in roll_feature_list if not x.startswith('TEAM1_win')]\n",
    "    \n",
    "    df = process_x_minus_league_avg(df, roll_feature_list, 'TEAM1')\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b992487-2cab-456e-89b6-4732e0292c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_new_features(df, df_consecutive):\n",
    "     \n",
    "    # add back all the new features created in the consecutive dataframe to the main dataframe\n",
    "    # all data for TEAM1 will be applied to the home team and then again to the visitor team\n",
    "    # except for head-to-head MATCHUP data, which will only be applied to home team (redundant to include for both)\n",
    "    # the letter '_x' will be appeneded to feature names when adding to home team\n",
    "    # the letter '_y' will be appended to feature names when adding to visitor team\n",
    "    # to match the existing convention in the dataset\n",
    "    \n",
    "    #first select out the new features\n",
    "    all_features = df_consecutive.columns.tolist()\n",
    "    link_features = ['GAME_ID', 'TEAM1', ]\n",
    "    redundant_features = ['GAME_DATE_EST','TEAM1_home','TEAM1_win','TEAM2','SEASON','PTS', 'FG_PCT', 'FT_PCT', 'FG3_PCT', 'AST', 'REB',]\n",
    "    matchup_features = [x for x in all_features if \"MATCHUP\" in x]\n",
    "    ignore_features = link_features + redundant_features\n",
    "    \n",
    "    new_features = [x for x in all_features if x not in ignore_features]\n",
    "    \n",
    "    # first home teams\n",
    "    \n",
    "    df1 = df_consecutive[df_consecutive['TEAM1_home'] == 1]\n",
    "    #add \"_x\" to new features\n",
    "    df1.columns = [x + '_x' if x in new_features else x for x in df1.columns]\n",
    "    #drop features that don't need to be merged\n",
    "    df1 = df1.drop(redundant_features,axis=1)\n",
    "    #change TEAM1 to HOME_TEAM_ID for easy merging\n",
    "    df1 = df1.rename(columns={'TEAM1': 'HOME_TEAM_ID'})\n",
    "    df = pd.merge(df, df1, how=\"left\", on=[\"GAME_ID\", \"HOME_TEAM_ID\"])\n",
    "    \n",
    "    #don't include matchup features for visitor team since they are equivant for both home and visitor\n",
    "    new_features = [x for x in new_features if x not in matchup_features]\n",
    "    df_consecutive = df_consecutive.drop(matchup_features,axis=1)\n",
    "    \n",
    "    # next visitor teams\n",
    "    \n",
    "    df2 = df_consecutive[df_consecutive['TEAM1_home'] == 0]\n",
    "    #add \"_y\" to new features\n",
    "    df2.columns = [x + '_y' if x in new_features else x for x in df2.columns]\n",
    "    #drop features that don't need to be merged\n",
    "    df2 = df2.drop(redundant_features,axis=1)\n",
    "    #change TEAM1 to VISITOR_TEAM_ID for easy merging\n",
    "    df2 = df2.rename(columns={'TEAM1': 'VISITOR_TEAM_ID'})\n",
    "    df = pd.merge(df, df2, how=\"left\", on=[\"GAME_ID\", \"VISITOR_TEAM_ID\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac89de67-9284-4b6b-897c-f27b747c73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_x_minus_y(df):\n",
    "    #Subtract visitor teams stats from the home teams stats for key fields\n",
    "    # field_x - field_y\n",
    "    \n",
    "    all_features = df.columns.tolist()\n",
    "    comparison_features = [x for x in all_features if \"_y\" in x]\n",
    "    \n",
    "    #don't include redunant features. (x - league_avg) - (y - league_avg) = x-y\n",
    "    comparison_features = [x for x in comparison_features if \"_MINUS_LEAGUE_AVG\" not in x]\n",
    "    \n",
    "    for feature in comparison_features:\n",
    "        feature_base = feature[:-2] #remove \"_y\" from the end\n",
    "        df[feature_base + \"_x_minus_y\"] = df[feature_base + \"_x\"] - df[feature_base + \"_y\"]\n",
    "        \n",
    "    #df = df.drop(\"CONFERENCE_x_minus_y\") #category variable not meaningful?\n",
    "        \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "763cc5a5-216b-490a-ada0-5c4f733aff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_rolling(df):\n",
    "    \n",
    "    # remove non-rolling features - these are data leaks\n",
    "    # they are stats from the actual game that decides winner/loser, \n",
    "    # but we don't know these stats before a game is played\n",
    "    \n",
    "    drop_columns =[]\n",
    "    \n",
    "    all_columns = df.columns.tolist()\n",
    "    \n",
    "    drop_columns1 = ['HOME_TEAM_WINS','PTS_home', 'FG_PCT_home', 'FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home']\n",
    "    drop_columns2 = ['PTS_away', 'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away', 'REB_away']\n",
    "    \n",
    "    drop_columns = drop_columns + drop_columns1\n",
    "    drop_columns = drop_columns + drop_columns2 \n",
    "    \n",
    "    use_columns = [item for item in all_columns if item not in drop_columns]\n",
    "    \n",
    "    return df[use_columns]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43bd7f16-7c11-438a-ac0c-9f4fd274fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_features(df):\n",
    "    \n",
    "    # lists for the number of games to including in rolling periods\n",
    "    #home_visitor_roll_list = [3, 5, 7, 10, 15]\n",
    "    #all_roll_list = [3, 5, 7, 10, 20, 40]\n",
    "    home_visitor_roll_list = [3, 15]\n",
    "    all_roll_list = [3, 20]\n",
    "        \n",
    "    df = remove_playoff_games(df)\n",
    "    df = fix_datatypes(df)\n",
    "    df = add_date_features(df)\n",
    "    df = add_rolling_home_visitor(df, \"HOME\", home_visitor_roll_list)\n",
    "    df = add_rolling_home_visitor(df, \"VISITOR\", home_visitor_roll_list)\n",
    "\n",
    "    #games must first be processed to sort all games in order per team\n",
    "    #regardless whether home or away\n",
    "    df_consecutive = process_games_consecutively(df)\n",
    "    df_consecutive = add_matchups(df_consecutive, home_visitor_roll_list)\n",
    "    df_consecutive = add_past_performance_all(df_consecutive, all_roll_list)\n",
    "\n",
    "    #add these features back to main dataframe\n",
    "    df = combine_new_features(df,df_consecutive)\n",
    "    \n",
    "    df['TARGET'] = df['HOME_TEAM_WINS']\n",
    "\n",
    "    \n",
    "    df = remove_non_rolling(df)\n",
    "    \n",
    "    df = process_x_minus_y(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d2db5-9767-40d5-bffe-714a84ecfd14",
   "metadata": {},
   "source": [
    "### Add Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "577e56a2-8224-4cc8-bfc1-89df0dcf6fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10598/2060600252.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'].shift() == 0] =  -1 * df[location + '_TEAM_WIN_STREAK']\n",
      "/tmp/ipykernel_10598/2060600252.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'].shift() == 0] =  -1 * df[location + '_TEAM_WIN_STREAK']\n",
      "/tmp/ipykernel_10598/4081270908.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['MATCHUP_WIN_STREAK'].loc[df['TEAM1_win'].shift() == 0] = -1 * df['MATCHUP_WIN_STREAK']\n",
      "/tmp/ipykernel_10598/1449406463.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['WIN_STREAK'].loc[df['TEAM1_win'].shift() == 0]  = -1 * df['WIN_STREAK']\n",
      "/tmp/ipykernel_10598/1449406463.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['HOME_AWAY_STREAK'].loc[df['TEAM1_home'].shift() == 0]  = -1 * df['HOME_AWAY_STREAK']\n",
      "/tmp/ipykernel_10598/2060600252.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'].shift() == 0] =  -1 * df[location + '_TEAM_WIN_STREAK']\n",
      "/tmp/ipykernel_10598/2060600252.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[location + '_TEAM_WIN_STREAK'].loc[df['HOME_TEAM_WINS'].shift() == 0] =  -1 * df[location + '_TEAM_WIN_STREAK']\n",
      "/tmp/ipykernel_10598/4081270908.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['MATCHUP_WIN_STREAK'].loc[df['TEAM1_win'].shift() == 0] = -1 * df['MATCHUP_WIN_STREAK']\n",
      "/tmp/ipykernel_10598/1449406463.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['WIN_STREAK'].loc[df['TEAM1_win'].shift() == 0]  = -1 * df['WIN_STREAK']\n",
      "/tmp/ipykernel_10598/1449406463.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['HOME_AWAY_STREAK'].loc[df['TEAM1_home'].shift() == 0]  = -1 * df['HOME_AWAY_STREAK']\n"
     ]
    }
   ],
   "source": [
    "train_features = add_all_features(train)\n",
    "test_features = add_all_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc1b53-e961-4415-bbc2-4cd0f9c427ba",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ada7682b-d7be-4786-b35c-0ea7b20b8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove 2nd to last season from test set\n",
    "#it was needed to just generate rolling mean that began in previous season\n",
    "\n",
    "latest_season = test_features['SEASON'].unique().max()\n",
    "test_features = test_features[test_features['SEASON'] >= (latest_season)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2ba3858-eddd-48d5-ba00-3e4aa8ce64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv(DATAPATH / \"processed\" / \"train_features.csv\",index=False)\n",
    "test_features.to_csv(DATAPATH / \"processed\" /\"test_features.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "4655998f62ad965cbd25df51edb717f2326f5df53d53899f0ae604225aa5ae06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
