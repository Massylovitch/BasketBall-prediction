{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddabba99",
   "metadata": {},
   "source": [
    "### Model Training Pipeline\n",
    "\n",
    "This notebook retrains the model and saves the model and performance metrics (Accuracy and AUC) to the Hopsworks.ai Model Registry.\n",
    "\n",
    "It executes Notebook 07 as part of the process and will use parameters as set there (GPU/no GPU, retune Hyperparameters or not, etc...). \n",
    "\n",
    "Notebook 07 is executed as a subprocess and the output is captured and displayed in this notebook. Notebook 07 is used instead of full conversion to py scripts because, while Neptune.ai experiment tracking is integrated in, I like to be able to also review the output in the notebook as well.\n",
    "\n",
    "\n",
    "This Notebook does the following:\n",
    " - Retrieves a train and test dataset from the Feature Store based upon on how many DAYS back from today you want to use as the test dataset.\n",
    " - Saves theses datasets as csv files in the data directory where Notebook 07 will expect to find them.\n",
    " - Executes Notebook 07 as a subprocess and captures the output.\n",
    " - Saves the model and performance metrics to the Hopsworks.ai Model Registry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc43e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548fdd0a-cd73-40ff-9154-6ca6a3233947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import hopsworks\n",
    "\n",
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "from hsfs.client.exceptions import RestAPIError\n",
    "\n",
    "import json\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# change working directory to project root when running from notebooks folder to make it easier to import modules\n",
    "# and to access sibling folders\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from pathlib import Path  # for Windows/Linux compatibility\n",
    "\n",
    "\n",
    "from src.utils.hopsworks_utils import (\n",
    "    convert_feature_names,\n",
    "    create_train_test_data,\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS_PATH = Path.cwd() / \"configs\"\n",
    "DATA_PATH = Path.cwd() / \"data\"\n",
    "NOTEBOOKS_PATH = Path.cwd() / \"notebooks\"\n",
    "MODELS_PATH = Path.cwd() / \"models\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ada0c87",
   "metadata": {},
   "source": [
    "**Parameters**\n",
    "\n",
    "Train and Test will be divided by date. The earliest chunk of data will be used as the train dataset and the last DAYS of data will be used as the test dataset.\n",
    "\n",
    "STARTDATE: The date to start the train dataset from. The train dataset will compose of all data from this date forward, leaving out the last number of DAYS as the test dataset.\n",
    "\n",
    "DAYS: The number of days to use as the test dataset. The test dataset will be the last DAYS days of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTDATE = \"2003-01-01\"  # start date \"YYYY-MM-DD\" for training data, data goes back to 2003 season \"2003-01-01\"\n",
    "DAYS = 30  # number of most recent days to use as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    HOPSWORKS_API_KEY = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "except:\n",
    "    raise Exception(\"Set environment variable HOPSWORKS_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dae0623f-03c7-42ef-82e3-9423d2a6f18c",
   "metadata": {},
   "source": [
    "**Connect to Hopsworks FeatureStore and Pull Train and Test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae7431-32cc-4231-a586-6de7d271dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = create_train_test_data(HOPSWORKS_API_KEY, STARTDATE, DAYS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e0137-057b-4d30-a9be-1e7e9b57192a",
   "metadata": {},
   "source": [
    "**Save data**\n",
    "\n",
    "As a convenience to re-use the existing model training notebook, the data is saved to files first (currently <100 megabytes total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86853294-5266-4950-90d7-826fbb626fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(DATA_PATH / \"processed\" / \"train_selected.csv\", index=False)\n",
    "test.to_csv(DATA_PATH / \"processed\" / \"test_selected.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e45361-eb90-4e37-8ef8-ca0d43b11e97",
   "metadata": {},
   "source": [
    "**Model Training**\n",
    "\n",
    "The existing model training notebook is re-used. It includes Neptune.ai experiment tracking for both training run and hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e34f67-4ad1-4194-9a0d-cacc526eb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebooks/07_model_testing.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b51112d-6319-4d72-8807-19a56e6abced",
   "metadata": {},
   "source": [
    "**Save to Model Registry**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11a54d-478e-4735-8d6a-4843f18964e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in train_predictions to create model schema\n",
    "train = pd.read_csv(DATA_PATH / \"processed\" / \"train_predictions.csv\")\n",
    "target = train[\"TARGET\"]\n",
    "drop_columns = [\"TARGET\", \"PredictionPct\", \"Prediction\"]\n",
    "train = train.drop(columns=drop_columns)\n",
    "\n",
    "input_schema = Schema(train)\n",
    "output_schema = Schema(target)\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "model_schema.to_dict()\n",
    "\n",
    "# read in model meta_data from training run\n",
    "with open(MODELS_PATH / \"model_data.json\", \"rb\") as fp:\n",
    "    model_data = json.load(fp)\n",
    "\n",
    "\n",
    "# # log back in to hopsworks.ai. Hyperparameter tuning may take hours.\n",
    "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "model = mr.sklearn.create_model(\n",
    "    name=model_data[\"model_name\"],\n",
    "    # metrics = model_data['metrics'],\n",
    "    description=(\n",
    "        model_data[\"model_name\"]\n",
    "        + \", calibration_method: \"\n",
    "        + model_data[\"calibration_method\"]\n",
    "        + \", brier_loss: \"\n",
    "        + str(model_data[\"brier_loss\"])\n",
    "    ),\n",
    "    model_schema=model_schema,\n",
    ")\n",
    "model.save(str(MODELS_PATH) + \"/model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f59e76-bdc1-433c-bfbd-891efc9c9da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basketball-prediction-klrE3EAW-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
