{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0097f2a4-79c5-4731-8570-6cb6630fc397",
   "metadata": {},
   "source": [
    "### Baseline Models\n",
    "\n",
    "Simple If-Then Models\n",
    "\n",
    " - Home team always wins \n",
    " \n",
    "ML Models\n",
    "\n",
    " - LightGBM \n",
    " - XGBoost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71787a4-84ae-44fc-bcaf-ea41b56807c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"XGB version:\", xgb.__version__)\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping\n",
    "from lightgbm import log_evaluation\n",
    "\n",
    "print(\"LGB version:\", lgb.__version__)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import shap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path  # for Windows/Linux compatibility\n",
    "\n",
    "DATAPATH = Path(r\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f46e0f-af90-49eb-a7b6-16ba9020744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATAPATH / \"processed\" / \"train.csv\")\n",
    "test = pd.read_csv(DATAPATH / \"processed\" / \"test.csv\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22804f68-1979-4173-8b7f-a2b28af87f83",
   "metadata": {},
   "source": [
    "**Model - Home team always wins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee0951a-c3b8-448c-bed8-f783dc9bd8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "\n",
    "predict = np.ones((train.shape[0],))\n",
    "true = train[\"TARGET\"]\n",
    "\n",
    "accuracy_score(true, predict), roc_auc_score(true, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c8a82-3f72-4804-b9bc-275cc051a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "\n",
    "predict = np.ones((test.shape[0],))\n",
    "true = test[\"TARGET\"]\n",
    "\n",
    "accuracy_score(true, predict), roc_auc_score(true, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac38807-8e97-433c-8e38-37b25bcd461b",
   "metadata": {},
   "source": [
    "### ML Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554abb2-d72b-45e9-b51d-f31f5aa8f3b6",
   "metadata": {},
   "source": [
    "**Fix Datatypes for smaller memory footprint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31953aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"GAME_DATE_EST\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de2db65-2803-45c0-831f-23423c610078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_datatypes(df):\n",
    "\n",
    "    if df.GAME_DATE_EST.dtype == \"O\":\n",
    "        df[\"GAME_DATE_EST\"] = df[\"GAME_DATE_EST\"].str.split(\" \").str[0]\n",
    "    df[\"GAME_DATE_EST\"] = pd.to_datetime(df[\"GAME_DATE_EST\"])\n",
    "\n",
    "    long_integer_fields = [\"GAME_ID\", \"HOME_TEAM_ID\", \"VISITOR_TEAM_ID\", \"SEASON\"]\n",
    "\n",
    "    # convert long integer fields to int32 from int64\n",
    "    for field in long_integer_fields:\n",
    "        df[field] = df[field].astype(\"int32\")\n",
    "\n",
    "    # convert the remaining int64s to int8\n",
    "    for field in df.select_dtypes(include=[\"int64\"]).columns.tolist():\n",
    "        df[field] = df[field].astype(\"int8\")\n",
    "\n",
    "    # convert float64s to float16s\n",
    "    for field in df.select_dtypes(include=[\"float64\"]).columns.tolist():\n",
    "        df[field] = df[field].astype(\"float16\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = fix_datatypes(train)\n",
    "test = fix_datatypes(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9b91832-9691-4cf3-a203-c6804c32c3da",
   "metadata": {},
   "source": [
    "**Basic Feature Engineering**\n",
    "\n",
    "Because the basic data is post-game data, there would be data leakage if we used the data as is. We need to create features that are available before the game starts. Namely, we will do a rolling average for each stat for the last 5 games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_means(df, location):\n",
    "\n",
    "    location_id = location + \"_TEAM_ID\"\n",
    "\n",
    "    # sort games by the order in which they were played for each home or visitor team\n",
    "    df = df.sort_values(\n",
    "        by=[location_id, \"GAME_DATE_EST\"],\n",
    "        axis=0,\n",
    "        ascending=[\n",
    "            True,\n",
    "            True,\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    # rolling means\n",
    "    feature_list = [\n",
    "        \"HOME_TEAM_WINS\",\n",
    "        \"PTS_home\",\n",
    "        \"FG_PCT_home\",\n",
    "        \"FT_PCT_home\",\n",
    "        \"FG3_PCT_home\",\n",
    "        \"AST_home\",\n",
    "        \"REB_home\",\n",
    "    ]\n",
    "\n",
    "    if location == \"VISITOR\":\n",
    "        feature_list = [\n",
    "            \"HOME_TEAM_WINS\",\n",
    "            \"PTS_away\",\n",
    "            \"FG_PCT_away\",\n",
    "            \"FT_PCT_away\",\n",
    "            \"FG3_PCT_away\",\n",
    "            \"AST_away\",\n",
    "            \"REB_away\",\n",
    "        ]\n",
    "\n",
    "    roll_feature_list = []\n",
    "    for feature in feature_list:\n",
    "        roll_feature_name = location + \"_\" + feature + \"_AVG_LAST_\" + \"5_\" + location\n",
    "        if feature == \"HOME_TEAM_WINS\":  # remove the \"HOME_\" for better readability\n",
    "            roll_feature_name = (\n",
    "                location + \"_\" + feature[5:] + \"_AVG_LAST_\" + \"5_\" + location\n",
    "            )\n",
    "        roll_feature_list.append(roll_feature_name)\n",
    "        df[roll_feature_name] = (\n",
    "            df.groupby([\"HOME_TEAM_ID\"])[feature]\n",
    "            .rolling(5, closed=\"left\")\n",
    "            .mean()\n",
    "            .values\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = add_rolling_means(train, \"HOME\")\n",
    "train = add_rolling_means(train, \"VISITOR\")\n",
    "test = add_rolling_means(test, \"HOME\")\n",
    "test = add_rolling_means(test, \"VISITOR\")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b91832-9691-4cf3-a203-c6804c32c3da",
   "metadata": {},
   "source": [
    "**Select Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd9743c-82cf-44bc-a297-58d3ae6d10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train[\"TARGET\"]\n",
    "test_target = test[\"TARGET\"]\n",
    "\n",
    "category_columns = [\n",
    "    \"HOME_TEAM_ID\",\n",
    "    \"VISITOR_TEAM_ID\",\n",
    "    \"SEASON\",\n",
    "    \"HOME_TEAM_WINS\",\n",
    "    \"PLAYOFF\",\n",
    "    \"CONFERENCE_x\",\n",
    "    \"CONFERENCE_y\",\n",
    "]\n",
    "\n",
    "all_columns = train.columns.tolist()\n",
    "drop_columns = [\n",
    "    \"TARGET\",\n",
    "    \"GAME_DATE_EST\",\n",
    "    \"GAME_ID\",\n",
    "]  # not really useful as-is\n",
    "\n",
    "# non-rolling features, which would be data leakage\n",
    "drop_columns1 = [\n",
    "    \"HOME_TEAM_WINS\",\n",
    "    \"PTS_home\",\n",
    "    \"FG_PCT_home\",\n",
    "    \"FT_PCT_home\",\n",
    "    \"FG3_PCT_home\",\n",
    "    \"AST_home\",\n",
    "    \"REB_home\",\n",
    "]\n",
    "drop_columns2 = [\n",
    "    \"PTS_away\",\n",
    "    \"FG_PCT_away\",\n",
    "    \"FT_PCT_away\",\n",
    "    \"FG3_PCT_away\",\n",
    "    \"AST_away\",\n",
    "    \"REB_away\",\n",
    "]\n",
    "\n",
    "drop_columns = drop_columns + drop_columns1\n",
    "drop_columns = drop_columns + drop_columns2\n",
    "\n",
    "use_columns = [item for item in all_columns if item not in drop_columns]\n",
    "\n",
    "train = train[use_columns]\n",
    "test = test[use_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d304655-f609-4512-b107-049cbeeb62a5",
   "metadata": {},
   "source": [
    "**Options**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508983c-17ad-4912-bf11-0916359d6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_FOLDS = 5\n",
    "SEED = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a036d-0f22-4b55-93f4-adf8acdfee10",
   "metadata": {},
   "source": [
    "### LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604599df-8c09-42f8-9a01-f74b4a949548",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "NUM_BOOST_ROUND = 700\n",
    "EARLY_STOPPING = 200\n",
    "LOG_EVALUATION = 100\n",
    "\n",
    "train_oof = np.zeros((train.shape[0],))\n",
    "test_preds = 0\n",
    "train_oof_shap = np.zeros((train.shape[0],train.shape[1]+1))\n",
    "#train_oof_shap_interact = np.zeros((train.shape[0],train.shape[1]+1,train.shape[1]+1))\n",
    "test_preds_shap = 0\n",
    "\n",
    "lgb_params= {\n",
    "            'seed': SEED,\n",
    "            'verbose': 0,           \n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc', \n",
    "            #'num_leaves': 31,\n",
    "            #'learning_rate': 0.05,\n",
    "            #'feature_fraction': 0.9,\n",
    "            #'bagging_fraction': 0.8,\n",
    "            #'bagging_freq': 5,\n",
    "\n",
    "            }\n",
    "\n",
    "\n",
    "# K-fold cross validation\n",
    "\n",
    "kf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train, target))):\n",
    "    \n",
    "    train_df, val_df = train.iloc[train_ind], train.iloc[val_ind]\n",
    "    train_target, val_target = target[train_ind], target[val_ind]\n",
    "\n",
    "    train_lgbdataset = lgb.Dataset(train_df, label=train_target,)\n",
    "    val_lgbdataset = lgb.Dataset(val_df, label=val_target, reference = train_lgbdataset )\n",
    "\n",
    "    model =  lgb.train(lgb_params, \n",
    "                       train_lgbdataset,\n",
    "                       valid_sets=val_lgbdataset,\n",
    "                       num_boost_round = NUM_BOOST_ROUND,\n",
    "                       callbacks=[log_evaluation(LOG_EVALUATION),early_stopping(EARLY_STOPPING,verbose=False)],\n",
    "                       #verbose_eval= VERBOSE_EVAL,\n",
    "                      )\n",
    "\n",
    "    temp_oof = model.predict(val_df)\n",
    "    temp_oof_shap = model.predict(val_df, pred_contrib=True)\n",
    "    \n",
    "    temp_test = model.predict(test)\n",
    "    temp_test_shap = model.predict(test, pred_contrib=True)\n",
    "\n",
    "    train_oof[val_ind] = temp_oof\n",
    "    test_preds += temp_test/K_FOLDS\n",
    "\n",
    "    train_oof_shap[val_ind, :] = temp_oof_shap\n",
    "    test_preds_shap += temp_test_shap/K_FOLDS\n",
    "    \n",
    "\n",
    "    #for accuracy score, prediction probabilities must be convert to binary scores (Win or Lose)\n",
    "    #determine optimum threshold for conveting probablities using ROC curve\n",
    "    #generally 0.5 works for balanced data\n",
    "    #fpr = false positive rate, tpr = true postive rate\n",
    "    fpr, tpr, thresholds = roc_curve(val_target,temp_oof)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    temp_oof_binary = (temp_oof > optimal_threshold).astype(int)\n",
    "\n",
    "    print(accuracy_score(val_target, temp_oof_binary), roc_auc_score(val_target, temp_oof))\n",
    "    \n",
    "\n",
    "    \n",
    "# Out-of-Fold composite for train data\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(target,train_oof)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "train_oof_binary = (train_oof > optimal_threshold).astype(int)\n",
    "\n",
    "print()\n",
    "print(\"Composite Train OOF CV Scores:\")\n",
    "print()\n",
    "print(\"Accuracy Score:\",accuracy_score(target, train_oof_binary))\n",
    "print(\"AUC Score:\", roc_auc_score(target, train_oof))\n",
    "print(\"Optimal Threshold:\", optimal_threshold)\n",
    "\n",
    "#scores for Test data\n",
    "\n",
    "test_preds_binary = (test_preds > optimal_threshold).astype(int)\n",
    "print()\n",
    "print(\"Test data Scores:\")\n",
    "print()\n",
    "print(\"Accuracy Score:\",accuracy_score(test_target, test_preds_binary))\n",
    "print(\"AUC Score:\", roc_auc_score(test_target, test_preds))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798bdbd-cc37-4c4b-8b0a-703068d946a4",
   "metadata": {},
   "source": [
    "**Feature Importance via Split - the number of times a feature is used in the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee054b40-a8eb-4c36-91b2-e5c90baddc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "lgb.plot_importance(model, importance_type=\"split\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b71ea-16a9-4b4a-8c47-91f4aeee5057",
   "metadata": {},
   "source": [
    "**Feature Importance via Gain - the average gain of splits which use the feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b7f21-a9e7-465b-8355-7b823801d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "lgb.plot_importance(model, importance_type=\"gain\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7902ba-edff-4039-942b-9c3bfa4e5a08",
   "metadata": {},
   "source": [
    "**Feature Importance via Shapley values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a9cd9-4f01-4f60-87bf-686ae5b2d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "shap.summary_plot(train_oof_shap[:, :-1], train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4e852-c79b-4e1a-964f-477461cd8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(train_oof_shap[:, :-1], train[use_columns], plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34042a79-5f67-4424-a2f3-4188d61c847b",
   "metadata": {},
   "source": [
    "### XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243dddf-9f3d-4104-94c3-c7255d296dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "NUM_BOOST_ROUND = 700\n",
    "\n",
    "train_oof = np.zeros((train.shape[0],))\n",
    "test_preds = 0\n",
    "train_oof_shap = np.zeros((train.shape[0],train.shape[1]+1))\n",
    "train_oof_shap_interact = np.zeros((train.shape[0],train.shape[1]+1,train.shape[1]+1))\n",
    "test_preds_shap = 0\n",
    "\n",
    "xgb_params= {\n",
    "            'seed': SEED,\n",
    "            'eval_metric': 'auc',\n",
    "             #'max_bin': 168, \n",
    "             #'max_depth': 1, #16\n",
    "             #'alpha': 6.956941489832698, \n",
    "             #'gamma': 0.6029881527116713, \n",
    "             #'reg_lambda': 2.527966510426255, \n",
    "             #'colsample_bytree': 0.9087064850010729, \n",
    "             #'subsample': 0.31410604106509005, \n",
    "             #'min_child_weight': 7.877326540625619,\n",
    "             #'num_parallel_tree' : 10,\n",
    "             #'learning_rate': 0.03,  \n",
    "            }\n",
    "\n",
    "# K-fold cross validation\n",
    "\n",
    "test_dmatrix = xgb.DMatrix(test)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train, target))):\n",
    "    \n",
    "    train_df, val_df = train.iloc[train_ind], train.iloc[val_ind]\n",
    "    train_target, val_target = target[train_ind], target[val_ind]\n",
    "\n",
    "    train_dmatrix = xgb.DMatrix(train_df, label=train_target)\n",
    "    val_dmatrix = xgb.DMatrix(val_df, label=val_target)\n",
    "\n",
    "    model =  xgb.train(xgb_params, \n",
    "                       train_dmatrix, \n",
    "                       num_boost_round = NUM_BOOST_ROUND,\n",
    "                      )\n",
    "\n",
    "    temp_oof = model.predict(val_dmatrix)\n",
    "    temp_oof_shap = model.predict(val_dmatrix, pred_contribs=True)\n",
    "    temp_oof_shap_interact = model.predict(val_dmatrix, pred_interactions=True)\n",
    "    \n",
    "    temp_test = model.predict(test_dmatrix)\n",
    "    temp_test_shap = model.predict(test_dmatrix, pred_contribs=True)\n",
    "\n",
    "    train_oof[val_ind] = temp_oof\n",
    "    test_preds += temp_test/K_FOLDS\n",
    "\n",
    "    train_oof_shap[val_ind, :] = temp_oof_shap\n",
    "    train_oof_shap_interact[val_ind, :,:] = temp_oof_shap_interact\n",
    "    test_preds_shap += temp_test_shap/K_FOLDS\n",
    "    \n",
    "    #for accuracy score, prediction probabilities must be convert to binary scores (Win or Lose)\n",
    "    #determine optimum threshold for conveting probablities using ROC curve\n",
    "    #generally 0.5 works for balanced data\n",
    "    #fpr = false positive rate, tpr = true postive rate\n",
    "    fpr, tpr, thresholds = roc_curve(val_target,temp_oof)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    temp_oof_binary = (temp_oof > optimal_threshold).astype(int)\n",
    "\n",
    "    print(accuracy_score(val_target, temp_oof_binary), roc_auc_score(val_target, temp_oof))\n",
    "    \n",
    "\n",
    "    \n",
    "# Out-of-Fold composite for train data\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(target,train_oof)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "train_oof_binary = (train_oof > optimal_threshold).astype(int)\n",
    "\n",
    "print()\n",
    "print(\"Composite Train OOF CV Scores:\")\n",
    "print()\n",
    "print(\"Accuracy Score:\",accuracy_score(target, train_oof_binary))\n",
    "print(\"AUC Score:\", roc_auc_score(target, train_oof))\n",
    "print(\"Optimal Threshold:\", optimal_threshold)\n",
    "\n",
    "#scores for Test data\n",
    "\n",
    "test_preds_binary = (test_preds > optimal_threshold).astype(int)\n",
    "print()\n",
    "print(\"Test data Scores:\")\n",
    "print()\n",
    "print(\"Accuracy Score:\",accuracy_score(test_target, test_preds_binary))\n",
    "print(\"AUC Score:\", roc_auc_score(test_target, test_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54938474-8284-45f7-bf60-51e2f65f92c5",
   "metadata": {},
   "source": [
    "**Feature Importance via Weight - the number of times a feature appears in a tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ff400-2b6d-440a-868c-7d9d5e5eeec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "xgb.plot_importance(model, importance_type=\"weight\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7ce051-7ccb-49f7-b666-564199579e3f",
   "metadata": {},
   "source": [
    "**Feature Importance via Gain - the average gain of splits which use the feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70612253-a661-40ca-8584-4de93c41e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "xgb.plot_importance(model, importance_type=\"gain\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fac593-df38-459f-b7d1-48a06a30258f",
   "metadata": {},
   "source": [
    "**Feature Importance via Shapley values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aded9c7-d089-4daf-9966-4c6eba368cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "shap.summary_plot(train_oof_shap[:, :-1], train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d737a84-793e-4a19-b36b-88462f4209ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(train_oof_shap[:, :-1], train[use_columns], plot_type=\"bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basketball-prediction-klrE3EAW-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
