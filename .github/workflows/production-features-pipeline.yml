name: production-features-pipeline

on:
  workflow_dispatch:
  schedule:
    - cron: '0 12 * * *'

jobs:
  scrape_features:
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo content
        uses: actions/checkout@v2

      - name: setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.12.3'
          
      - name: install python packages
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          python -m pip install jupyter nbconvert nbformat
      
      - name: Remove Chrome
        run: sudo apt purge google-chrome-stable
      - name: Remove default Chromium
        run: sudo apt purge chromium-browser
      - name: Install a new Chromium
        run: sudo apt install -y chromium-browser
      - name: Install all necessary packages
        run: pip install requests beautifulsoup4 pandas webdriver-manager selenium
      - name: Run the scraping script
        run: python scraper.py
        
            
      - name: execute python workflows from notebook
        env: 
          HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
          NEPTUNE_API_TOKEN: ${{ secrets.NEPTUNE_API_TOKEN }}
          SCRAPINGANT_API_KEY: ${{ secrets.SCRAPINGANT_API_KEY }}
          PYTHONUNBUFFERED: "1"
          
        run:
          jupyter nbconvert --to notebook --execute notebooks/09_production_features_pipeline.ipynb  --output ../notebook_executed

      - name: commit updated notebook
        uses: EndBug/add-and-commit@v7
        with:
          author_name: MG
          message: "Update Notebook"
          add: "notebook_executed.ipynb"
